{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    " \n",
    "# Initialize spacy 'en' model, keeping only component needed for lemmatization and creating an engine\n",
    "# https://spacy.io/models\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>more like funchuck</td>\n",
       "      <td>Gave this to my dad for a gag gift after direc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Inspiring</td>\n",
       "      <td>I hope a lot of people hear this cd. We need m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>The best soundtrack ever to anything.</td>\n",
       "      <td>I'm reading a lot of reviews saying that this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Chrono Cross OST</td>\n",
       "      <td>The music of Yasunori Misuda is without questi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Too good to be true</td>\n",
       "      <td>Probably the greatest soundtrack in history! U...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                           review_title  \\\n",
       "0      3                     more like funchuck   \n",
       "1      5                              Inspiring   \n",
       "2      5  The best soundtrack ever to anything.   \n",
       "3      4                       Chrono Cross OST   \n",
       "4      5                    Too good to be true   \n",
       "\n",
       "                                         review_text  \n",
       "0  Gave this to my dad for a gag gift after direc...  \n",
       "1  I hope a lot of people hear this cd. We need m...  \n",
       "2  I'm reading a lot of reviews saying that this ...  \n",
       "3  The music of Yasunori Misuda is without questi...  \n",
       "4  Probably the greatest soundtrack in history! U...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show table with pandas\n",
    "import pandas as pd\n",
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gave this to my dad for a gag gift after directing \"Nunsense,\" he got a reall kick out of it!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_text = df.iloc[0]['review_text']\n",
    "review_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/vhugobarnes/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gave', 'this', 'to', 'my', 'dad', 'for', 'a', 'gag', 'gift', 'after', 'directing', '``', 'Nunsense', ',', \"''\", 'he', 'got', 'a', 'reall', 'kick', 'out', 'of', 'it', '!']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Using nltk tokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    " \n",
    "# Download punkt module\n",
    "nltk.download('punkt')\n",
    "print(word_tokenize(review_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gave',\n",
       " 'this',\n",
       " 'to',\n",
       " 'my',\n",
       " 'dad',\n",
       " 'for',\n",
       " 'a',\n",
       " 'gag',\n",
       " 'gift',\n",
       " 'after',\n",
       " 'directing',\n",
       " 'Nunsense',\n",
       " 'he',\n",
       " 'got',\n",
       " 'a',\n",
       " 'reall',\n",
       " 'kick',\n",
       " 'out',\n",
       " 'of',\n",
       " 'it']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    " \n",
    "# Tokenization and remove punctuations\n",
    "words = [str(token) for token in nlp(review_text) if not token.is_punct]\n",
    " \n",
    "# Remove digits and others symbols except @ (emails)\n",
    "words = [re.sub(r\"[^A-Za-z@]\", \"\", word) for word in words]\n",
    " \n",
    "# Remove websites and email address\n",
    "words = [re.sub(r\"\\S+com\", \"\", word) for word in words]\n",
    "words = [re.sub(r\"\\S@\\S+\", \"\", word) for word in words]\n",
    " \n",
    "# Remove empty spaces\n",
    "words = [word for word in words if word != ' ']\n",
    " \n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/vhugobarnes/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['gave', 'dad', 'gag', 'gift', 'directing', 'nunsense', 'got', 'reall', 'kick']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import stopwords from nltk\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# Change all stopwords into lowercase\n",
    "stopwords_lower = [s.lower() for s in stopwords]\n",
    "\n",
    "# Exclude stopwords from the reviews\n",
    "words = [word.lower() for word in words if word.lower() not in stopwords_lower]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'cat', 'be', 'play', 'in', 'the', 'yard']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization\n",
    "example_phrase = \"the cats are playing in the yard\"\n",
    "words = [token.lemma_ for token in nlp(example_phrase) if not token.is_punct]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(str_input):\n",
    "  # Tokenization, remove punctuation, lemmatization\n",
    "  words = [token.lemma_ for token in nlp(str_input) if not token.is_punct]\n",
    "\n",
    "  # Remove symbols, websites and email addresses\n",
    "  words = [re.sub(r\"[^A-Za-z@]\", \"\", word) for word in words]\n",
    "  words = [re.sub(r\"\\S+com\", \"\", word) for word in words]\n",
    "  words = [re.sub(r\"\\S+@\\S+\", \"\", word) for word in words]\n",
    "  words = [word for word in words if word != ' ']\n",
    "  words = [word for word in words if len(word) != 0]\n",
    "\n",
    "  # Remove stopwords\n",
    "  words = [word.lower() for word in words if word.lower() not in stopwords_lower]\n",
    "\n",
    "  # Combine a list into one string\n",
    "  string = \" \".join(words)\n",
    "\n",
    "  return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "#? We create a new file where the preprocessed reviews will be written on\n",
    "preprocessed_train_file = open(\"preprocessed_train.csv\", \"a\")\n",
    "# Write down headers\n",
    "preprocessed_train_file.write(\"index,review_title,review_text\\n\");\n",
    "\n",
    "#? Open the train.csv file\n",
    "train_csv = open(\"train.csv\", \"r\")\n",
    "\n",
    "# We pass the first line to\n",
    "csv_reader = csv.reader(train_csv)\n",
    "\n",
    "# Loop though the file and preprocess data\n",
    "#! Just 10,000 rows because 600,000 are too much for a regular computer\n",
    "counter = 0\n",
    "for row in csv_reader:\n",
    "  if counter <= 10000:\n",
    "    index = row[0]\n",
    "    review_title = text_preprocessing(row[1])\n",
    "    review_text = text_preprocessing(row[2])\n",
    "\n",
    "    new_row = '{},{},{}\\n'.format(index, review_title, review_text)\n",
    "    preprocessed_train_file.write(new_row)\n",
    "    counter += 1\n",
    "  else:\n",
    "    break\n",
    "\n",
    "preprocessed_train_file.close()\n",
    "train_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#? We create a new file where the preprocessed reviews will be written on\n",
    "preprocessed_test_file = open(\"preprocessed_test.csv\", \"a\")\n",
    "# Write down headers\n",
    "preprocessed_test_file.write(\"index,review_title,review_text\\n\");\n",
    "\n",
    "#? Open the train.csv file\n",
    "test_csv = open(\"test.csv\", \"r\")\n",
    "\n",
    "# We pass the first line to\n",
    "csv_reader = csv.reader(test_csv)\n",
    "\n",
    "# Loop though the file and preprocess data\n",
    "#! Just 10,000 rows because 600,000 are too much for a regular computer\n",
    "counter = 0\n",
    "for row in csv_reader:\n",
    "  if counter <= 10000:\n",
    "    index = row[0]\n",
    "    review_title = text_preprocessing(row[1])\n",
    "    review_text = text_preprocessing(row[2])\n",
    "\n",
    "    new_row = '{},{},{}\\n'.format(index, review_title, review_text)\n",
    "    preprocessed_test_file.write(new_row)\n",
    "    counter += 1\n",
    "  else:\n",
    "    break\n",
    "\n",
    "preprocessed_test_file.close()\n",
    "test_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "291b2d5982e0999966c953e04f8e35501f7937c40d49c02c39bbc523f029ae6f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
